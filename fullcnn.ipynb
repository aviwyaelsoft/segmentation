{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation ,Conv2D ,BatchNormalization , Dense ,Dropout ,Flatten ,MaxPool2D ,GlobalMaxPool2D ,GlobalAveragePooling2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aviw/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/aviw/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
      "/home/aviw/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(160,320,1)),\n",
    "            Conv2D(32,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            Conv2D(32,(3,3), activation='relu'),\n",
    "            MaxPool2D((2,2)),\n",
    "            BatchNormalization(axis=1),\n",
    "            Conv2D(64,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            Conv2D(64,(3,3), activation='relu'),\n",
    "            MaxPool2D((2,2)),\n",
    "            BatchNormalization(axis=1),\n",
    "            Conv2D(128,(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            Conv2D(128,(3,3), activation='relu'),\n",
    "            MaxPool2D((2,2)),\n",
    "            BatchNormalization(axis=1),\n",
    "            Conv2D(128,(3,3), activation='relu'),\n",
    "           \n",
    "            BatchNormalization(axis=1),\n",
    "        Conv2D(128 ,(3,3), activation='relu', border_mode='same'),\n",
    "        MaxPool2D((2,2)),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(128 ,(3,3), activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        \n",
    "        Conv2D(4 ,(3,3), border_mode='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Activation('softmax')\n",
    "           \n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def white (img):\n",
    "    x=random.randint(1, 1000)\n",
    "    return img+x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_11 (Batc (None, 160, 320, 1)       640       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 158, 318, 32)      320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 158, 318, 32)      632       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 156, 316, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 78, 158, 32)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 78, 158, 32)       312       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 76, 156, 64)       18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 76, 156, 64)       304       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 74, 154, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 37, 77, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 37, 77, 64)        148       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 35, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 35, 75, 128)       140       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 33, 73, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16, 36, 128)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 34, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 14, 34, 128)       56        \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 34, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 17, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 7, 17, 128)        28        \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 7, 17, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 7, 17, 128)        28        \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 7, 17, 4)          4612      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 736,148\n",
      "Trainable params: 734,972\n",
      "Non-trainable params: 1,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "gen=image.ImageDataGenerator( rotation_range=15,shear_range=0.1 ,channel_shift_range=0.2,\n",
    "     width_shift_range=0.4 , height_shift_range=0.25)\n",
    "gen1=image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5820 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "\n",
    "train= gen.flow_from_directory('train', target_size=(160,320),\n",
    "                class_mode='categorical', shuffle=True, batch_size=batch_size, color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1098 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val= gen1.flow_from_directory('val', target_size=(160,320),\n",
    "                class_mode='categorical', shuffle=False, batch_size=batch_size, color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "model.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "194/194 [==============================] - 584s - loss: 1.2721 - acc: 0.4167 - val_loss: 1.4697 - val_acc: 0.1803\n",
      "Epoch 2/3\n",
      "194/194 [==============================] - 569s - loss: 1.1981 - acc: 0.4768 - val_loss: 1.6062 - val_acc: 0.2714\n",
      "Epoch 3/3\n",
      " 46/194 [======>.......................] - ETA: 320s - loss: 1.1517 - acc: 0.5043"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "model.fit_generator(train, steps_per_epoch=5820/batch_size, epochs=3, \n",
    "                            validation_data=val, validation_steps=1098/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=5, \n",
    "                            validation_data=val, validation_steps=594/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights ('fcnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=5, \n",
    "                            validation_data=val, validation_steps=594/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.01\n",
    "model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=5, \n",
    "                            validation_data=val, validation_steps=594/batch_size)\n",
    "model.save_weights ('fcnn3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=5, \n",
    "                            validation_data=val, validation_steps=594/batch_size)\n",
    "model.save_weights ('fcnn4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001\n",
    "model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=5, \n",
    "                            validation_data=val, validation_steps=594/batch_size)\n",
    "model.save_weights ('fcnn5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=5, \n",
    "                            validation_data=val, validation_steps=594/batch_size)\n",
    "model.save_weights ('fcnn6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001\n",
    "for i in range (7,17):\n",
    "    model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=1, \n",
    "                            validation_data=val, validation_steps=594/batch_size)\n",
    "    model.save_weights ('fcnn{x}.h5'.format(x=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.fit_generator(train, steps_per_epoch=2387/batch_size, epochs=1, \n",
    "                            validation_data=val, validation_steps=594/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights ('fcnn16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = gen.flow_from_directory('newtest', target_size=(160,320),\n",
    "                class_mode='binary', shuffle=False, batch_size=1 ,color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre=model.predict_generator(test,115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = test.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mistake=0\n",
    "doubt=0\n",
    "file=[]\n",
    "file1=[]\n",
    "correct=0\n",
    "num=0\n",
    "for x in pre :\n",
    "    \n",
    "    if x[0]<0.8 and x[0]>0.2: \n",
    "        doubt+=1\n",
    "        print (x , \"doubt\")\n",
    "        file1.append (files[num])\n",
    "    else:\n",
    "        if num<0:\n",
    "            if x[0]<0.8: \n",
    "                mistake+=1\n",
    "                print (x,num)\n",
    "                file.append (files[num])\n",
    "            else : correct+=1\n",
    "        else:\n",
    "            if x[1]<0.8: \n",
    "                mistake+=1\n",
    "                print (x,num) \n",
    "                file.append (files[num])\n",
    "            else : correct+=1\n",
    "    num+=1\n",
    "    \n",
    "all=correct+mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doubt/(all+doubt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mistake/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.load_img ('test/'+files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = gen.flow_from_directory('newtest', target_size=(160,320),\n",
    "                class_mode=None, shuffle=False, batch_size=1 , color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train= gen.flow_from_directory('train', target_size=(160,320),\n",
    "                class_mode=None, shuffle=False, batch_size=1, color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train1=np.concatenate([train.next() for i in range(train.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test1=np.concatenate([test.next() for i in range(test.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot(img):\n",
    "    plt.imshow(to_plot(img))\n",
    "\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "def to_plot(img):\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        return np.rollaxis(img, 0, 1).astype(np.uint8)\n",
    "    else:\n",
    "        return np.rollaxis(img, 0, 3).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "l =model.layers\n",
    "conv_fn = K.function([model.layers[0].input, K.learning_phase()],\n",
    "                                  [model.layers[-3].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[x,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conv = conv_fn([train1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= test1[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.array_to_img (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre [pic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "inp = np.expand_dims(test1[pic], 0)\n",
    "conv = conv_fn([inp,0])\n",
    "conv=conv[0]\n",
    "print (conv.shape)\n",
    "show=np.swapaxes(conv,2,3)\n",
    "show=np.swapaxes(show,1,2)\n",
    "show=show[0]\n",
    "print (show.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "show=scipy.misc.imresize (show[1],size=(160,320))\n",
    "print (show.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.reshape (test1[pic] , (160,320))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image.array_to_img (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow (x ,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.reshape (test1[pic] , (160,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow (x ,cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow (show , cmap=\"cool\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(x ,cmap=\"gray\", alpha=1)\n",
    "plt.imshow(show, cmap=\"cool\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
