{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "traingen=image.ImageDataGenerator(  rotation_range=15,shear_range=0.1  ,width_shift_range=0.4 , height_shift_range=0.25)\n",
    "vallabelgen=image.ImageDataGenerator(rescale=1./255)\n",
    "valgen=image.ImageDataGenerator()\n",
    "trainlabelgen=image.ImageDataGenerator(rescale=1./255, rotation_range=15,shear_range=0.1  ,width_shift_range=0.4 , height_shift_range=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark= vallabelgen.flow_from_directory('dark', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=1,color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dark=np.concatenate([dark.next() for i in range(dark.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= traingen.flow_from_directory('train/images', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=1)\n",
    "\n",
    "train1=np.concatenate([train.next() for i in range(train.samples)])\n",
    "\n",
    "train= traingen.flow_from_directory('train/images', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=2)\n",
    "\n",
    "train2=np.concatenate([train.next() for i in range(train.samples)])\n",
    "\n",
    "train= traingen.flow_from_directory('train/images', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=3)\n",
    "\n",
    "train3=np.concatenate([train.next() for i in range(train.samples)])\n",
    "\n",
    "train= traingen.flow_from_directory('train/images', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=4)\n",
    "\n",
    "train4=np.concatenate([train.next() for i in range(train.samples)])\n",
    "\n",
    "train= traingen.flow_from_directory('train/images', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=5)\n",
    "\n",
    "train5=np.concatenate([train.next() for i in range(train.samples)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= trainlabelgen.flow_from_directory('train/labels', target_size=(160,320),\n",
    "                class_mode=None,  batch_size=1, seed=1,color_mode='grayscale')\n",
    "labels1=np.concatenate([labels.next() for i in range(labels.samples)])\n",
    "\n",
    "labels= trainlabelgen.flow_from_directory('train/labels', target_size=(160,320),\n",
    "                class_mode=None,  batch_size=1, seed=2,color_mode='grayscale')\n",
    "labels2=np.concatenate([labels.next() for i in range(labels.samples)])\n",
    "\n",
    "labels= trainlabelgen.flow_from_directory('train/labels', target_size=(160,320),\n",
    "                class_mode=None,  batch_size=1, seed=3,color_mode='grayscale')\n",
    "labels3=np.concatenate([labels.next() for i in range(labels.samples)])\n",
    "\n",
    "labels= trainlabelgen.flow_from_directory('train/labels', target_size=(160,320),\n",
    "                class_mode=None,  batch_size=1, seed=4,color_mode='grayscale')\n",
    "labels4=np.concatenate([labels.next() for i in range(labels.samples)])\n",
    "\n",
    "labels= trainlabelgen.flow_from_directory('train/labels', target_size=(160,320),\n",
    "                class_mode=None,  batch_size=1, seed=5,color_mode='grayscale')\n",
    "labels5=np.concatenate([labels.next() for i in range(labels.samples)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (25):\n",
    "    print (train.filenames[i] , labels.filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.array_to_img (train1[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.array_to_img (mask1[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_f=train.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lab_f=labels.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (25):\n",
    "    print (lab_f[i], \"   \",trn_f[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "os.path.isfile(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cam1-081943.230_label.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path=\"test/labels/ra/\"\n",
    "for filename in os.listdir(path):\n",
    "    print (filename)\n",
    "    if filename.endswith(\"_label.jpg\"):\n",
    "        os.rename(path+filename, path+filename[:-10]+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images belonging to 3 classes.\n",
      "Found 6 images belonging to 3 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5d59fa19613d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m val_labels= vallabelgen.flow_from_directory('val/labels', target_size=(160,320),\n\u001b[1;32m      4\u001b[0m                 class_mode=None,  batch_size=1, seed=1,color_mode='grayscale')\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mval1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mval_labels1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "val= valgen.flow_from_directory('val/images', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=1)\n",
    "val_labels= vallabelgen.flow_from_directory('val/labels', target_size=(160,320),\n",
    "                class_mode=None,  batch_size=1, seed=1,color_mode='grayscale')\n",
    "val1=np.concatenate([val.next() for i in range(val.samples)])\n",
    "val_labels1=np.concatenate([val_labels.next() for i in range(val_labels.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (6):\n",
    "    print (val.filenames[i], \"   \",val_labels.filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dark=dark[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= traingen.flow_from_directory('train/images', target_size=(160,320),\n",
    "                class_mode=\"categorical\", batch_size=1, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lb=classes.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dark=dark*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask1=[]\n",
    "for i in range (25):\n",
    "    x=[]\n",
    "    for j in range (3):\n",
    "        if lb[i]==j:x.append(labels1[i])\n",
    "        else:x.append(dark)\n",
    "    mask1.append(x)\n",
    "    \n",
    "mask2=[]\n",
    "for i in range (25):\n",
    "    x=[]\n",
    "    for j in range (3):\n",
    "        if lb[i]==j:x.append(labels2[i])\n",
    "        else:x.append(dark)\n",
    "    mask2.append(x)\n",
    "\n",
    "mask3=[]\n",
    "for i in range (25):\n",
    "    x=[]\n",
    "    for j in range (3):\n",
    "        if lb[i]==j:x.append(labels3[i])\n",
    "        else:x.append(dark)\n",
    "    mask3.append(x)\n",
    "    \n",
    "mask4=[]\n",
    "for i in range (25):\n",
    "    x=[]\n",
    "    for j in range (3):\n",
    "        if lb[i]==j:x.append(labels4[i])\n",
    "        else:x.append(dark)\n",
    "    mask4.append(x)\n",
    "    \n",
    "mask5=[]\n",
    "for i in range (25):\n",
    "    x=[]\n",
    "    for j in range (3):\n",
    "        if lb[i]==j:x.append(labels5[i])\n",
    "        else:x.append(dark)\n",
    "    mask5.append(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask1=np.array (mask1)\n",
    "mask2=np.array (mask2)\n",
    "mask3=np.array (mask3)\n",
    "mask4=np.array (mask4)\n",
    "mask5=np.array (mask5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask1=np.reshape (mask1 , (25,3,160,320))\n",
    "mask2=np.reshape (mask2 , (25,3,160,320))\n",
    "mask3=np.reshape (mask3 , (25,3,160,320))\n",
    "mask4=np.reshape (mask4 , (25,3,160,320))\n",
    "mask5=np.reshape (mask5 , (25,3,160,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask1=np.swapaxes(mask1,1,2)\n",
    "mask1=np.swapaxes(mask1,2,3)\n",
    "\n",
    "mask2=np.swapaxes(mask2,1,2)\n",
    "mask2=np.swapaxes(mask2,2,3)\n",
    "\n",
    "mask3=np.swapaxes(mask3,1,2)\n",
    "mask3=np.swapaxes(mask3,2,3)\n",
    "\n",
    "mask4=np.swapaxes(mask4,1,2)\n",
    "mask4=np.swapaxes(mask4,2,3)\n",
    "\n",
    "mask5=np.swapaxes(mask5,1,2)\n",
    "mask5=np.swapaxes(mask5,2,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 [0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.array_to_img (mask1[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valclasses= valgen.flow_from_directory('val/images', target_size=(160,320),\n",
    "                class_mode=\"categorical\", batch_size=1, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vallb=valclasses.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valmask=[]\n",
    "for i in range (6):\n",
    "    x=[]\n",
    "    for j in range (3):\n",
    "        if lb[i]==j:x.append(val_labels1[i])\n",
    "        else:x.append(dark)\n",
    "    valmask.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valmask=np.array (valmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valmask=np.reshape (valmask , (6,3,160,320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valmask=np.swapaxes(valmask,1,2)\n",
    "valmask=np.swapaxes(valmask,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2DTranspose ,concatenate, Input,Activation ,Conv2D ,BatchNormalization , Dense ,Dropout ,Flatten ,MaxPool2D ,GlobalMaxPool2D ,GlobalAveragePooling2D\n",
    "from keras.models import Sequential ,Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "    inputs = Input((160, 320, 3))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPool2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPool2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    \n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(3, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model=get_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sparse_accuracy_ignoring_last_label(y_true, y_pred):\n",
    "    nb_classes = K.int_shape(y_pred)[-1]\n",
    "    y_pred = K.reshape(y_pred, (-1, nb_classes))\n",
    "\n",
    "    y_true = K.one_hot(tf.to_int32(K.flatten(y_true)),\n",
    "                       nb_classes + 1)\n",
    "    unpacked = tf.unstack(y_true, axis=-1)\n",
    "    legal_labels = ~tf.cast(unpacked[-1], tf.bool)\n",
    "    y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "\n",
    "    return K.sum(tf.to_float(legal_labels & K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))) / K.sum(tf.to_float(legal_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_sparse_crossentropy_ignoring_last_label(y_true, y_pred):\n",
    "    y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "    log_softmax = tf.nn.log_softmax(y_pred)\n",
    "\n",
    "    y_true = K.one_hot(tf.to_int32(K.flatten(y_true)), K.int_shape(y_pred)[-1]+1)\n",
    "    unpacked = tf.unstack(y_true, axis=-1)\n",
    "    y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "\n",
    "    cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "    cross_entropy_mean = K.mean(cross_entropy)\n",
    "\n",
    "    return cross_entropy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = softmax_sparse_crossentropy_ignoring_last_label\n",
    "metrics = [sparse_accuracy_ignoring_last_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001\n",
    "for i in range (100):\n",
    "    for j in range (3):\n",
    "        batch=5**j\n",
    "        print (\"round--\" , i )\n",
    "        model.fit (train1,mask1 , batch_size=batch , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "        model.fit (train2,mask2 , batch_size=batch , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "        model.fit (train3,mask3 , batch_size=batch , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "        model.fit (train4,mask4 , batch_size=batch , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "        model.fit (train5,mask5 , batch_size=batch , epochs=1, shuffle=True , validation_data= (val1,valmask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range (20):\n",
    "    print (\"round--\" , i )\n",
    "    model.fit (train1,mask1 , batch_size=25 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train2,mask2 , batch_size=25 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train3,mask3 , batch_size=25 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train4,mask4 , batch_size=25 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train5,mask5 , batch_size=25 , epochs=1, shuffle=True , validation_data= (val1,valmask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001\n",
    "for i in range (100):\n",
    "    print (\"round--\" , i )\n",
    "    model.fit (train1,mask1 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train2,mask2 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train3,mask3 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train4,mask4 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train5,mask5 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.1\n",
    "for i in range (100):\n",
    "    model.fit (train1,mask1 , batch_size=1 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train2,mask2 , batch_size=1 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train3,mask3 , batch_size=1 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train4,mask4 , batch_size=1 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "    model.fit (train5,mask5 , batch_size=1 , epochs=1, shuffle=True , validation_data= (val1,valmask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit (train1,mask1 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "model.fit (train5,mask5 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "model.fit (train2,mask2 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "model.fit (train3,mask3 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n",
    "model.fit (train4,mask4 , batch_size=5 , epochs=1, shuffle=True , validation_data= (val1,valmask))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights ('unetsig25_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= valgen.flow_from_directory('test/images', target_size=(160,320),\n",
    "                class_mode=None, batch_size=1, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file=test.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre=model.predict_generator (test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.array_to_img (pre[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show=pre[img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show=np.swapaxes(show,1,2)\n",
    "show=np.swapaxes(show,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.load_img ('test/images/'+file[img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(show[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = valgen.flow_from_directory('test/images', target_size=(160,320),\n",
    "                class_mode=None, shuffle=False, batch_size=1  )\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "test1=np.concatenate([test.next() for i in range(test.samples)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=test1[img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.swapaxes(x,1,2)\n",
    "x=np.swapaxes(x,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(x[img] ,cmap=\"gray\", alpha=1)\n",
    "plt.imshow(pre[img], cmap=\"cool\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
