{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import keras\n",
    "from keras.models import Model ,Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, GlobalAveragePooling2D ,Conv2D ,Activation , Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846486939797218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PIL\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL.ImageOps import equalize as eq\n",
    "import random\n",
    "random.uniform(0.01, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from PIL.ImageOps import equalize as eq\n",
    "\n",
    "def white (img):\n",
    "    img=image.array_to_img (img)\n",
    "    img= eq(img)\n",
    "    return image.img_to_array (img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lap (img):\n",
    "    img=image.array_to_img (img).convert('RGB') \n",
    " \n",
    "    open_cv_image = np.array(img) \n",
    "# Convert RGB to BGR \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
    "    laplacian = cv2.Laplacian(open_cv_image,cv2.CV_64F)\n",
    "    \n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug (img):\n",
    "    x=lap (img)\n",
    "    \n",
    "    return white(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150, 300, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_190 (Bat (None, 150, 300, 3)       12        \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         (None, 3, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 8196      \n",
      "=================================================================\n",
      "Total params: 21,810,992\n",
      "Trainable params: 21,776,554\n",
      "Non-trainable params: 34,438\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_height = 150\n",
    "img_width = 300\n",
    "img_channels =3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "\n",
    "def inceptionv3(img_dim=img_dim):\n",
    "    input_tensor = Input(shape=img_dim)\n",
    "    base_model = InceptionV3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_shape=img_dim)\n",
    "    bn = BatchNormalization()(input_tensor)\n",
    "    x = base_model(bn)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(4, activation='softmax')(x)\n",
    "    model = Model(input_tensor, output)\n",
    "    return model\n",
    "\n",
    "model = inceptionv3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "gen=image.ImageDataGenerator(rotation_range=30,shear_range=0.2, preprocessing_function=lap )\n",
    "gen1=image.ImageDataGenerator(preprocessing_function=lap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5820 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=20\n",
    "\n",
    "train= gen.flow_from_directory('train', target_size=(150,300),\n",
    "                class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1098 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "val= gen1.flow_from_directory('val', target_size=(150,300),\n",
    "                class_mode='categorical', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', \n",
    "                      metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "291/291 [==============================] - 173s - loss: 1.0513 - acc: 0.5562 - val_loss: 1.5124 - val_acc: 0.3215\n",
      "Epoch 2/3\n",
      "291/291 [==============================] - 172s - loss: 0.7982 - acc: 0.6763 - val_loss: 1.6718 - val_acc: 0.3078\n",
      "Epoch 3/3\n",
      "291/291 [==============================] - 176s - loss: 0.6938 - acc: 0.7284 - val_loss: 2.0893 - val_acc: 0.3033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0969f5f7b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=20\n",
    "model.fit_generator(train, steps_per_epoch=5820/batch_size, epochs=3, \n",
    "                            validation_data=val, validation_steps=1098/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "291/291 [==============================] - 207s - loss: 1.0510 - acc: 0.5529 - val_loss: 1.4761 - val_acc: 0.3306\n",
      "Epoch 2/3\n",
      "268/291 [==========================>...] - ETA: 14s - loss: 0.9449 - acc: 0.6047"
     ]
    }
   ],
   "source": [
    "batch_size=20\n",
    "model.optimizer.lr=0.1\n",
    "model.fit_generator(train, steps_per_epoch=5820/batch_size, epochs=3, \n",
    "                            validation_data=val, validation_steps=1098/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 115 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test = gen1.flow_from_directory('newtest', target_size=(150,300),\n",
    "                class_mode='binary', shuffle=False, batch_size=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre=model.predict_generator(test,115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = test.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.66085073e-07] 0\n",
      "[ 0.00159416] 1\n",
      "[ 0.0004852] 2\n",
      "[ 0.00022313] 3\n",
      "[  3.69669328e-06] 4\n",
      "[  4.51046738e-08] 5\n",
      "[ 0.00041703] 6\n",
      "[  8.60614382e-05] 7\n",
      "[  6.33264135e-05] 8\n",
      "[ 0.00012839] 9\n",
      "[ 0.00131503] 10\n",
      "[ 0.00097508] 11\n",
      "[ 0.00084794] 12\n",
      "[  1.15112935e-05] 13\n",
      "[  5.33862476e-05] 14\n",
      "[ 0.00045947] 15\n",
      "[  6.98463846e-05] 16\n",
      "[  2.17293891e-05] 17\n",
      "[  3.77711367e-05] 18\n",
      "[  2.36685264e-06] 19\n",
      "[  2.27249302e-06] 20\n",
      "[ 0.00051964] 21\n",
      "[  6.70497830e-05] 22\n",
      "[ 0.00185021] 23\n",
      "[  5.28199453e-05] 24\n",
      "[ 0.00023212] 25\n",
      "[  2.04589342e-05] 26\n",
      "[  2.93554021e-05] 27\n",
      "[ 0.00051169] 28\n",
      "[  3.21427081e-07] 29\n",
      "[  3.94702038e-05] 30\n",
      "[  7.11783941e-05] 31\n",
      "[  1.29871232e-05] 32\n",
      "[ 0.00088638] 33\n",
      "[  4.66361307e-05] 34\n",
      "[ 0.00021132] 35\n",
      "[ 0.00128563] 36\n",
      "[ 0.00456053] 37\n",
      "[ 0.00010767] 38\n",
      "[ 0.00027094] 39\n",
      "[  3.59039109e-06] 40\n",
      "[ 0.00011883] 41\n",
      "[  8.23270966e-05] 42\n",
      "[  2.87157927e-05] 43\n",
      "[  6.00116482e-06] 44\n",
      "[ 0.00206607] 45\n",
      "[ 0.00011634] 46\n",
      "[ 0.00110863] 47\n",
      "[  1.97718805e-06] 48\n",
      "[ 0.00555313] 49\n",
      "[ 0.00027946] 50\n",
      "[ 0.00031836] 51\n",
      "[ 0.0034342] 52\n",
      "[  3.59948899e-05] 53\n",
      "[  2.73577939e-06] 54\n",
      "[  1.00997604e-05] 55\n",
      "[  3.11946792e-06] 56\n",
      "[ 0.00050972] 57\n",
      "[  5.58075990e-05] 58\n",
      "[ 0.00041511] 59\n",
      "[  7.25590507e-05] 60\n",
      "[ 0.0087583] 61\n",
      "[  7.50840127e-06] 62\n",
      "[  9.81832636e-05] 63\n",
      "[ 0.00016215] 64\n",
      "[  2.11876227e-06] 65\n",
      "[  5.03842966e-06] 66\n",
      "[ 0.00266354] 67\n",
      "[ 0.00010965] 68\n",
      "[  2.72700511e-08] 69\n",
      "[ 0.05072986] 70\n",
      "[  6.90133602e-05] 71\n",
      "[ 0.00140345] 72\n",
      "[ 0.00046486] 73\n",
      "[  8.24046310e-06] 74\n",
      "[ 0.00082294] 75\n",
      "[  6.94288246e-05] 76\n",
      "[ 0.00537603] 77\n",
      "[ 0.00029891] 78\n",
      "[ 0.02978506] 79\n",
      "[ 0.0240534] 80\n",
      "[  2.70902228e-06] 81\n",
      "[  1.40162274e-06] 82\n",
      "[  3.46349722e-08] 83\n",
      "[ 0.000185] 84\n",
      "[  2.17375364e-05] 85\n",
      "[  1.91083586e-06] 86\n",
      "[  4.22608318e-05] 87\n",
      "[ 0.00023352] 88\n",
      "[  5.06272613e-07] 89\n",
      "[ 0.00025352] 90\n",
      "[ 0.00084621] 91\n",
      "[ 0.01775762] 92\n",
      "[ 0.00029089] 93\n",
      "[ 0.00274566] 94\n",
      "[  1.82578412e-06] 95\n",
      "[  4.37190995e-09] 96\n",
      "[ 0.00073679] 97\n",
      "[ 0.00394051] 98\n",
      "[ 0.00170851] 99\n",
      "[ 0.00010098] 100\n",
      "[ 0.0284298] 101\n",
      "[ 0.00396818] 102\n",
      "[  2.10909619e-08] 103\n",
      "[  3.69852815e-09] 104\n",
      "[ 0.00168666] 105\n",
      "[ 0.00060058] 106\n",
      "[ 0.02799368] 107\n",
      "[  3.42405292e-05] 108\n",
      "[ 0.00031114] 109\n",
      "[ 0.00039588] 110\n",
      "[ 0.00153002] 111\n",
      "[ 0.00020634] 112\n",
      "[ 0.00036652] 113\n",
      "[ 0.0156057] 114\n"
     ]
    }
   ],
   "source": [
    "mistake=0\n",
    "doubt=0\n",
    "file=[]\n",
    "file1=[]\n",
    "correct=0\n",
    "num=0\n",
    "for x in pre :\n",
    "    \n",
    "    if x[0]<0.8 and x[0]>0.2: \n",
    "        doubt+=1\n",
    "        print (x , \"doubt\")\n",
    "        file1.append (files[num])\n",
    "    else:\n",
    "        if num<0:\n",
    "            if x[0]>0.8: \n",
    "                mistake+=1\n",
    "                print (x,num)\n",
    "                file.append (files[num])\n",
    "            else : correct+=1\n",
    "        else:\n",
    "            if x[0]<0.8: \n",
    "                mistake+=1\n",
    "                print (x,num) \n",
    "                file.append (files[num])\n",
    "            else : correct+=1\n",
    "    num+=1\n",
    "    \n",
    "all=correct+mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01680672268907563"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubt/(all+doubt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
